# -*- coding: utf-8 -*-
"""
voice_checker.py

ê°„ë‹¨í•œ ìŒì„± í™”ì í™•ì¸ ë„êµ¬
- ìŒì„± íŒŒì¼ í•˜ë‚˜ ì—…ë¡œë“œ â†’ ê¸°ì¡´ í™”ìì¸ì§€ í™•ì¸
- ìˆìœ¼ë©´ ëˆ„êµ¬ì¸ì§€ ì•Œë ¤ì£¼ê³ , ì—†ìœ¼ë©´ "ìƒˆë¡œìš´ í™”ì" ë¦¬í„´
"""

import torch
import numpy as np
from pyannote.audio import Model
import librosa
import pickle
import glob
import os
from sklearn.metrics.pairwise import cosine_similarity

class VoiceChecker:
    """ê°„ë‹¨í•œ ìŒì„± í™”ì í™•ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.known_speakers = {}
        
        print("ğŸ™ï¸ ìŒì„± í™”ì í™•ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
        
        # ê¸°ì¡´ í™”ì ë°ì´í„° ë¡œë“œ
        self._load_speakers()
    
    def _load_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        try:
            model_path = "models/pyannote_model_wespeaker-voxceleb-resnet34-LM.bin"
            self.model = Model.from_pretrained(model_path)
            
            if torch.cuda.is_available():
                self.model = self.model.cuda()
            
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_speakers(self):
        """ê¸°ì¡´ í™”ì ë°ì´í„° ë¡œë“œ (embeddings.pkl íŒŒì¼ ì‚¬ìš©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ)"""
        try:
            # embeddings íŒŒì¼ë“¤ ì°¾ê¸°
            embeddings_files = glob.glob("embeddings/*_embeddings.pkl")
            profile_files = glob.glob("embeddings/*_profile.pkl")
            
            if not embeddings_files:
                print("âš ï¸ ë“±ë¡ëœ í™”ìê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € test.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
                return
            
            print(f"ğŸ“Š ê°œë³„ ì„ë² ë”© íŒŒì¼ ì‚¬ìš©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ ëª¨ë“œ")
            
            for embeddings_file in embeddings_files:
                try:
                    # embeddings ë°ì´í„° ë¡œë“œ
                    with open(embeddings_file, 'rb') as f:
                        embeddings_data = pickle.load(f)
                    
                    # í™”ì ID ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
                    filename = os.path.basename(embeddings_file)
                    # ì˜ˆ: 20250826_042213_SPEAKER_00_embeddings.pkl
                    parts = filename.split('_')
                    if len(parts) >= 4:
                        speaker_id = f"{parts[2]}_{parts[3]}"  # SPEAKER_00
                    else:
                        speaker_id = parts[2] if len(parts) > 2 else "UNKNOWN"
                    
                    # í•´ë‹¹í•˜ëŠ” profileë„ ë¡œë“œ (ë©”íƒ€ë°ì´í„°ìš©)
                    profile_file = embeddings_file.replace('_embeddings.pkl', '_profile.pkl')
                    profile_data = {}
                    if os.path.exists(profile_file):
                        with open(profile_file, 'rb') as f:
                            profile_data = pickle.load(f)
                    
                    # ëª¨ë“  ì„ë² ë”© ë²¡í„°ë“¤ ì¶”ì¶œ
                    all_embeddings = []
                    for emb_data in embeddings_data:
                        all_embeddings.append(emb_data['embedding'])
                    
                    self.known_speakers[speaker_id] = {
                        'speaker_id': speaker_id,
                        'all_embeddings': np.array(all_embeddings),  # ëª¨ë“  ê°œë³„ ì„ë² ë”©ë“¤
                        'num_segments': len(all_embeddings),
                        'total_duration': profile_data.get('total_duration', 0),
                        'mean_embedding': profile_data.get('mean_embedding'),  # ë°±ì—…ìš©
                        'embeddings_data': embeddings_data  # ìƒì„¸ ì •ë³´
                    }
                    
                    print(f"âœ… {speaker_id}: {len(all_embeddings)}ê°œ ê°œë³„ ì„ë² ë”© ë¡œë“œ")
                    
                except Exception as e:
                    print(f"âŒ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({embeddings_file}): {e}")
            
            print(f"âœ… ì´ {len(self.known_speakers)}ëª…ì˜ í™”ì ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ê³ ì •í™•ë„ ëª¨ë“œ)")
            
        except Exception as e:
            print(f"âŒ í™”ì ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def check_voice(self, audio_file):
        """
        ìŒì„± íŒŒì¼ í™•ì¸
        
        Args:
            audio_file: í™•ì¸í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: í™•ì¸ ê²°ê³¼
        """
        
        print(f"\nğŸµ ìŒì„± íŒŒì¼ í™•ì¸: {audio_file}")
        
        if not os.path.exists(audio_file):
            return {"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}"}
        
        if not self.known_speakers:
            return {"error": "ë“±ë¡ëœ í™”ìê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            # 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ë¡œë“œ
            audio_data, sample_rate = librosa.load(audio_file, sr=16000)
            duration = len(audio_data) / sample_rate
            
            print(f"ğŸ“ ìŒì„± ê¸¸ì´: {duration:.1f}ì´ˆ")
            
            # ë„ˆë¬´ ì§§ì€ íŒŒì¼ ì²´í¬
            if duration < 0.5:
                return {"error": f"ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({duration:.1f}ì´ˆ). ìµœì†Œ 0.5ì´ˆ í•„ìš”"}
            
            # 2ë‹¨ê³„: ì„ë² ë”© ì¶”ì¶œ
            print("ğŸ”„ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
            embedding = self._extract_embedding(audio_data)
            
            if embedding is None:
                return {"error": "ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨"}
            
            # 3ë‹¨ê³„: í™”ì í™•ì¸ (ê¸°ë³¸ì ìœ¼ë¡œ best_match ë°©ë²• ì‚¬ìš©)
            result = self._find_speaker(embedding, threshold=0.6, method="best_match")
            
            # 4ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥
            self._print_result(result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": str(e)}
    
    def _extract_embedding(self, audio_data):
        """ì„ë² ë”© ì¶”ì¶œ"""
        try:
            # ë„ˆë¬´ ê¸´ ê²½ìš° ì¤‘ê°„ ë¶€ë¶„ë§Œ ì‚¬ìš© (ìµœëŒ€ 10ì´ˆ)
            if len(audio_data) > 10 * 16000:
                start_idx = len(audio_data) // 2 - 5 * 16000
                end_idx = len(audio_data) // 2 + 5 * 16000
                audio_data = audio_data[start_idx:end_idx]
            
            # í…ì„œ ë³€í™˜
            audio_tensor = torch.from_numpy(audio_data).float()
            audio_tensor = audio_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, samples)
            
            if torch.cuda.is_available():
                audio_tensor = audio_tensor.cuda()
            
            # ì„ë² ë”© ì¶”ì¶œ
            with torch.no_grad():
                embedding = self.model(audio_tensor)
            
            return embedding.cpu().numpy().flatten()
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _find_speaker(self, test_embedding, threshold=0.6, method="best_match"):
        """
        í™”ì ì°¾ê¸° (ê°œë³„ ì„ë² ë”©ë“¤ê³¼ ë¹„êµë¡œ ì •í™•ë„ í–¥ìƒ)
        
        Args:
            test_embedding: í…ŒìŠ¤íŠ¸ ì„ë² ë”© ë²¡í„°
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            method: ë¹„êµ ë°©ë²•
                - "best_match": ê°€ì¥ ìœ ì‚¬í•œ ì„¸ê·¸ë¨¼íŠ¸ì™€ ë¹„êµ
                - "average": ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì™€ì˜ í‰ê·  ìœ ì‚¬ë„
                - "top_k": ìƒìœ„ Kê°œ ì„¸ê·¸ë¨¼íŠ¸ í‰ê·  (K=3)
        """
        
        if test_embedding.ndim == 1:
            test_embedding = test_embedding.reshape(1, -1)
        
        best_speaker = None
        best_similarity = 0
        similarity_details = {}
        
        print(f"ğŸ” í™”ì ì‹ë³„ ì¤‘... (ë°©ë²•: {method})")
        
        # ëª¨ë“  ë“±ë¡ëœ í™”ìì™€ ë¹„êµ
        for speaker_id, speaker_data in self.known_speakers.items():
            all_embeddings = speaker_data['all_embeddings']  # (N, 256) í˜•íƒœ
            num_segments = speaker_data['num_segments']
            
            # ê° ê°œë³„ ì„ë² ë”©ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = []
            for i, stored_embedding in enumerate(all_embeddings):
                stored_embedding = stored_embedding.reshape(1, -1)
                sim = cosine_similarity(test_embedding, stored_embedding)[0][0]
                similarities.append(sim)
            
            # ë°©ë²•ë³„ë¡œ ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚°
            if method == "best_match":
                # ê°€ì¥ ìœ ì‚¬í•œ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©
                final_similarity = max(similarities)
                best_segment_idx = similarities.index(final_similarity)
                
            elif method == "average":
                # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì™€ì˜ í‰ê·  ìœ ì‚¬ë„
                final_similarity = np.mean(similarities)
                best_segment_idx = similarities.index(max(similarities))
                
            elif method == "top_k":
                # ìƒìœ„ 3ê°œ ì„¸ê·¸ë¨¼íŠ¸ í‰ê· 
                k = min(3, len(similarities))
                top_k_similarities = sorted(similarities, reverse=True)[:k]
                final_similarity = np.mean(top_k_similarities)
                best_segment_idx = similarities.index(max(similarities))
            
            # ìƒì„¸ ì •ë³´ ì €ì¥
            similarity_details[speaker_id] = {
                'final_similarity': final_similarity,
                'best_segment_similarity': max(similarities),
                'average_similarity': np.mean(similarities),
                'num_segments': num_segments,
                'best_segment_idx': best_segment_idx,
                'all_similarities': similarities
            }
            
            # ìµœê³  ìœ ì‚¬ë„ ì—…ë°ì´íŠ¸
            if final_similarity > best_similarity:
                best_similarity = final_similarity
                best_speaker = speaker_id
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š í™”ìë³„ ìœ ì‚¬ë„ ë¶„ì„:")
        for speaker_id, details in similarity_details.items():
            status = "âœ…" if details['final_similarity'] >= threshold else "âŒ"
            print(f"{status} {speaker_id}: {details['final_similarity']:.4f} "
                  f"(ìµœê³ : {details['best_segment_similarity']:.4f}, "
                  f"í‰ê· : {details['average_similarity']:.4f}, "
                  f"{details['num_segments']}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
        
        # ê²°ê³¼ íŒë‹¨
        if best_similarity >= threshold:
            confidence = "ë§¤ìš° ë†’ìŒ" if best_similarity >= 0.9 else "ë†’ìŒ" if best_similarity >= 0.8 else "ë³´í†µ"
            
            return {
                "found": True,
                "speaker": best_speaker,
                "similarity": best_similarity,
                "confidence": confidence,
                "method": method,
                "details": similarity_details[best_speaker],
                "all_details": similarity_details
            }
        else:
            return {
                "found": False,
                "speaker": None,
                "similarity": best_similarity,
                "confidence": "ë‚®ìŒ",
                "method": method,
                "all_details": similarity_details
            }
    
    def _print_result(self, result):
        """ê²°ê³¼ ì¶œë ¥ (ê³ ì •í™•ë„ ëª¨ë“œ ì •ë³´ í¬í•¨)"""
        print(f"\nğŸ¯ === ê³ ì •í™•ë„ í™”ì ì‹ë³„ ê²°ê³¼ ===")
        
        if "error" in result:
            print(f"âŒ ì˜¤ë¥˜: {result['error']}")
            return
        
        if result["found"]:
            print(f"âœ… ê¸°ì¡´ í™”ì ë°œê²¬!")
            print(f"ğŸ‘¤ í™”ì: {result['speaker']}")
            print(f"ğŸ“Š ìµœì¢… ìœ ì‚¬ë„: {result['similarity']:.4f}")
            print(f"ğŸ¯ ì‹ ë¢°ë„: {result['confidence']}")
            print(f"ğŸ” ë¹„êµ ë°©ë²•: {result['method']}")
            
            # ìƒì„¸ ì •ë³´ ì¶œë ¥
            if 'details' in result:
                details = result['details']
                print(f"ğŸ“ˆ ìƒì„¸ ë¶„ì„:")
                print(f"   - ìµœê³  ì„¸ê·¸ë¨¼íŠ¸ ìœ ì‚¬ë„: {details['best_segment_similarity']:.4f}")
                print(f"   - í‰ê·  ìœ ì‚¬ë„: {details['average_similarity']:.4f}")
                print(f"   - ë¹„êµí•œ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {details['num_segments']}ê°œ")
                
                # ê°€ì¥ ìœ ì‚¬í•œ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
                best_idx = details['best_segment_idx']
                if hasattr(self, 'known_speakers') and result['speaker'] in self.known_speakers:
                    embeddings_data = self.known_speakers[result['speaker']].get('embeddings_data', [])
                    if best_idx < len(embeddings_data):
                        best_segment = embeddings_data[best_idx]
                        print(f"   - ê°€ì¥ ìœ ì‚¬í•œ ì„¸ê·¸ë¨¼íŠ¸: {best_segment['start_time']:.1f}s-{best_segment['end_time']:.1f}s")
                        print(f"   - í•´ë‹¹ í…ìŠ¤íŠ¸: '{best_segment['text'][:50]}{'...' if len(best_segment['text']) > 50 else ''}'")
        else:
            print(f"â“ ìƒˆë¡œìš´ í™”ìì…ë‹ˆë‹¤")
            print(f"ğŸ“Š ìµœê³  ìœ ì‚¬ë„: {result['similarity']:.4f} (ì„ê³„ê°’: 0.6 ë¯¸ë§Œ)")
            print(f"ğŸ’¡ ë“±ë¡ëœ ëª¨ë“  í™”ìì™€ ê°œë³„ ë¹„êµí–ˆì§€ë§Œ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
            # ê°€ì¥ ê°€ê¹Œìš´ í™”ì ì •ë³´
            if 'all_details' in result:
                all_details = result['all_details']
                closest_speaker = max(all_details.items(), key=lambda x: x[1]['final_similarity'])
                print(f"ğŸ” ê°€ì¥ ê°€ê¹Œìš´ í™”ì: {closest_speaker[0]} (ìœ ì‚¬ë„: {closest_speaker[1]['final_similarity']:.4f})")
    
    def check_voice_advanced(self, audio_file, method="best_match", threshold=0.6):
        """
        ê³ ê¸‰ í™”ì í™•ì¸ (ë°©ë²• ì„ íƒ ê°€ëŠ¥)
        
        Args:
            audio_file: ìŒì„± íŒŒì¼ ê²½ë¡œ
            method: ë¹„êµ ë°©ë²• ("best_match", "average", "top_k")
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
        """
        print(f"\nğŸµ ê³ ì •í™•ë„ ìŒì„± íŒŒì¼ í™•ì¸: {audio_file}")
        print(f"ğŸ”§ ë¹„êµ ë°©ë²•: {method}, ì„ê³„ê°’: {threshold}")
        
        if not os.path.exists(audio_file):
            return {"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}"}
        
        if not self.known_speakers:
            return {"error": "ë“±ë¡ëœ í™”ìê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            audio_data, sample_rate = librosa.load(audio_file, sr=16000)
            duration = len(audio_data) / sample_rate
            
            print(f"ğŸ“ ìŒì„± ê¸¸ì´: {duration:.1f}ì´ˆ")
            
            if duration < 0.5:
                return {"error": f"ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({duration:.1f}ì´ˆ). ìµœì†Œ 0.5ì´ˆ í•„ìš”"}
            
            # ì„ë² ë”© ì¶”ì¶œ
            print("ğŸ”„ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
            embedding = self._extract_embedding(audio_data)
            
            if embedding is None:
                return {"error": "ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨"}
            
            # í™”ì í™•ì¸ (ê³ ê¸‰ ë°©ë²• ì‚¬ìš©)
            result = self._find_speaker(embedding, threshold, method)
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_result(result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": str(e)}

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    print("ğŸ™ï¸ ê°„ë‹¨ ìŒì„± í™”ì í™•ì¸ ë„êµ¬")
    print("="*40)
    
    checker = VoiceChecker()
    
    if len(sys.argv) > 1:
        # ëª…ë ¹í–‰ì—ì„œ íŒŒì¼ ì§€ì •
        audio_file = sys.argv[1]
        result = checker.check_voice(audio_file)
        
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        while True:
            print(f"\nğŸ“ ìŒì„± íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: quit)")
            audio_file = input("íŒŒì¼ ê²½ë¡œ: ").strip()
            
            if audio_file.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                break
            
            if not audio_file:
                # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
                test_files = [
                    "temp/20250826_025237_SPEAKER_00_010.wav",
                    "temp/20250826_025237_SPEAKER_01_008.wav",
                    "audio/test.wav"
                ]
                
                print(f"\nğŸ§ª ê¸°ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤:")
                for i, file in enumerate(test_files, 1):
                    if os.path.exists(file):
                        print(f"{i}. {file}")
                        result = checker.check_voice(file)
                        print()
                
            else:
                result = checker.check_voice(audio_file)

if __name__ == "__main__":
    main()
