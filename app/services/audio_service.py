"""
ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê´€ë ¨ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
í™”ì ë¶„ë¦¬, STT, í™”ì ê²€ì¦ ë“±ì˜ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ë‹´ë‹¹
"""
import os
import tempfile
import time
import torch
import whisper
import librosa
import soundfile as sf
import pickle
import numpy as np
import json
from datetime import datetime
from collections import defaultdict
from sklearn.metrics.pairwise import cosine_similarity
from pyannote.audio import Pipeline
import glob

from app.services.s3_service import S3Service
from app.services.speaker_service import SpeakerService
from app.models.speaker_model import SpeakerModel


class AudioProcessingService:
    """ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.pipeline = None
        self.whisper_model = None
        self.device = None
        self.s3_service = S3Service()
        self.speaker_service = SpeakerService()
        
    def initialize_models(self):
        """AI ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
        if self.pipeline is None:
            print("ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # GPU ì„¤ì •
            if torch.cuda.is_available():
                self.device = torch.device("cuda")
                print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
            else:
                self.device = torch.device("cpu")
                print("CPU ëª¨ë“œë¡œ ì‹¤í–‰")
            
            # í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            self.pipeline = Pipeline.from_pretrained("models/pyannote_diarization_config.yaml")
            self.pipeline.to(self.device)
            print("í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
            
            # Whisper ëª¨ë¸ ë¡œë“œ
            self.whisper_model = whisper.load_model("large-v3")
            self.whisper_model = self.whisper_model.to(self.device)
            print("Whisper STT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def convert_audio_to_wav(self, original_file_path, timestamp):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        print("ì˜¤ë””ì˜¤ íŒŒì¼ì„ WAVë¡œ ë³€í™˜ ì¤‘...")
        try:
            # librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì •ê·œí™” (16kHz, mono)
            audio_data, original_sr = librosa.load(original_file_path, sr=16000, mono=True)
            
            # WAV íŒŒì¼ë¡œ ì €ì¥
            wav_filename = f"{timestamp}_converted.wav"
            wav_file_path = os.path.join('temp/uploads', wav_filename)
            
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(wav_file_path), exist_ok=True)
            
            sf.write(wav_file_path, audio_data, 16000)
            
            print(f"WAV ë³€í™˜ ì™„ë£Œ: {wav_file_path}")
            return wav_file_path
            
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ íŒŒì¼ ì‚¬ìš©
            return original_file_path
    
    def perform_speaker_diarization(self, file_path):
        """í™”ì ë¶„ë¦¬ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰"""
        print("í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì‹œì‘...")
        start_time = time.time()
        
        try:
            # íŒŒì´í”„ë¼ì¸ ë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ì„¤ì •í•˜ì—¬ í…ì„œ í¬ê¸° ë¶ˆì¼ì¹˜ ë¬¸ì œ ë°©ì§€
            original_batch_size = getattr(self.pipeline._segmentation, 'batch_size', None)
            if hasattr(self.pipeline._segmentation, 'batch_size'):
                self.pipeline._segmentation.batch_size = 1
            
            if hasattr(self.pipeline._embedding, 'batch_size'):
                self.pipeline._embedding.batch_size = 1
                
            diarization = self.pipeline(file_path)
            
            # ì›ë˜ ë°°ì¹˜ í¬ê¸°ë¡œ ë³µì›
            if original_batch_size is not None and hasattr(self.pipeline._segmentation, 'batch_size'):
                self.pipeline._segmentation.batch_size = original_batch_size
                
        except Exception as e:
            print(f"í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë” ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
            try:
                print("ì•ˆì „ ëª¨ë“œë¡œ ì¬ì‹œë„ ì¤‘...")
                # ë” ì‘ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                if hasattr(self.pipeline, '_segmentation') and hasattr(self.pipeline._segmentation, 'step'):
                    original_step = self.pipeline._segmentation.step
                    self.pipeline._segmentation.step = 0.25  # 0.25ì´ˆ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                    
                diarization = self.pipeline(file_path)
                
                # ì›ë˜ ì„¤ì • ë³µì›
                if 'original_step' in locals():
                    self.pipeline._segmentation.step = original_step
                    
            except Exception as e2:
                print(f"ì•ˆì „ ëª¨ë“œ ì¬ì‹œë„ë„ ì‹¤íŒ¨: {e2}")
                raise Exception(f"í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)} / ì¬ì‹œë„ ì‹¤íŒ¨: {str(e2)}")
        
        diarization_time = time.time() - start_time
        return diarization, diarization_time
    
    def perform_speech_to_text(self, file_path, diarization):
        """ê° í™”ìë³„ êµ¬ê°„ì— ëŒ€í•´ STT ì²˜ë¦¬ë¥¼ ìˆ˜í–‰"""
        stt_start_time = time.time()
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
        audio_data, sample_rate = librosa.load(file_path, sr=None)
        results = []
        
        for i, (turn, _, speaker) in enumerate(diarization.itertracks(yield_label=True)):
            start_sample = int(turn.start * sample_rate)
            end_sample = int(turn.end * sample_rate)
            
            # í•´ë‹¹ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ ì¶”ì¶œ
            segment_audio = audio_data[start_sample:end_sample]
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Whisper STT ìˆ˜í–‰
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                sf.write(temp_file.name, segment_audio, sample_rate)
                
                # Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ STT ìˆ˜í–‰
                try:
                    result = self.whisper_model.transcribe(temp_file.name, language="ko")
                    text = result["text"].strip()
                    
                    results.append({
                        "start": float(turn.start),
                        "end": float(turn.end),
                        "speaker": speaker,
                        "text": text,
                        "duration": float(turn.end - turn.start)
                    })
                    
                except Exception as e:
                    print(f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    results.append({
                        "start": float(turn.start),
                        "end": float(turn.end),
                        "speaker": speaker,
                        "text": "[STT ì²˜ë¦¬ ì‹¤íŒ¨]",
                        "duration": float(turn.end - turn.start)
                    })
                finally:
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    os.unlink(temp_file.name)
        
        stt_time = time.time() - stt_start_time
        return results, stt_time
    
    def extract_single_segment_embedding(self, audio_file, segment_result):
        """ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ì¶”ì¶œ (ë¹ ë¥¸ ê²€ì¦ìš©)"""
        try:
            # ì„ë² ë”© ëª¨ë¸ ì¶”ì¶œ
            embedding_model = self.pipeline._embedding
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
            audio_data, sample_rate = librosa.load(audio_file, sr=16000)
            
            start_time = segment_result["start"]
            end_time = segment_result["end"]
            
            # í•´ë‹¹ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ ì¶”ì¶œ
            start_sample = int(start_time * sample_rate)
            end_sample = int(end_time * sample_rate)
            segment_audio = audio_data[start_sample:end_sample]
            
            # ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ì œì™¸
            if len(segment_audio) < sample_rate * 0.5:
                return None
            
            # ì„ë² ë”© ì¶”ì¶œ
            if hasattr(embedding_model, 'model_'):
                direct_model = embedding_model.model_
            else:
                from pyannote.audio import Model
                model_path = "models/pyannote_model_wespeaker-voxceleb-resnet34-LM.bin"
                direct_model = Model.from_pretrained(model_path)
                if torch.cuda.is_available():
                    direct_model = direct_model.cuda()
            
            # í…ì„œ ë³€í™˜
            audio_tensor = torch.from_numpy(segment_audio).float()
            audio_tensor = audio_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, samples)
            
            if torch.cuda.is_available():
                audio_tensor = audio_tensor.cuda()
            
            # ì„ë² ë”© ì¶”ì¶œ
            with torch.no_grad():
                embedding = direct_model(audio_tensor)
            
            return embedding.cpu().numpy().flatten()
            
        except Exception as e:
            print(f"âŒ ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_next_speaker_id(self, embeddings_dir="temp/embeddings"):
        """ë‹¤ìŒ ì‚¬ìš© ê°€ëŠ¥í•œ í™”ì IDë¥¼ ë°˜í™˜ (SPEAKER_XX í˜•ì‹)"""
        try:
            os.makedirs(embeddings_dir, exist_ok=True)
            
            # ê¸°ì¡´ í”„ë¡œíŒŒì¼ íŒŒì¼ë“¤ì—ì„œ ì‚¬ìš©ëœ ID ì¶”ì¶œ
            profile_files = glob.glob(f"{embeddings_dir}/*_profile.pkl")
            used_ids = set()
            
            for profile_file in profile_files:
                try:
                    # íŒŒì¼ëª…ì—ì„œ SPEAKER_XX íŒ¨í„´ ì¶”ì¶œ
                    filename = os.path.basename(profile_file)
                    if filename.startswith('SPEAKER_') and '_profile.pkl' in filename:
                        speaker_part = filename.split('_profile.pkl')[0]
                        used_ids.add(speaker_part)
                except:
                    continue
            
            # ë‹¤ìŒ ì‚¬ìš© ê°€ëŠ¥í•œ ID ì°¾ê¸°
            counter = 0
            while True:
                new_id = f"SPEAKER_{counter:02d}"
                if new_id not in used_ids:
                    return new_id
                counter += 1
                
        except Exception as e:
            print(f"í™”ì ID ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return f"SPEAKER_{int(time.time()) % 1000:03d}"  # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ fallback
    
    def extract_and_save_embeddings(self, audio_file, results, target_speakers=None):
        """
        í™”ìë³„ ì„ë² ë”© ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜
        target_speakers: ì €ì¥í•  ëŒ€ìƒ í™”ì ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  í™”ì)
        """
        if target_speakers:
            # ìƒˆë¡œìš´ í™”ì IDë“¤ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ë¡œê·¸ì— í‘œì‹œ
            embeddings_dir = "temp/embeddings"
            os.makedirs(embeddings_dir, exist_ok=True)
            
            # ê¸°ì¡´ ì‚¬ìš©ëœ IDë“¤ í™•ì¸
            profile_files = glob.glob(f"{embeddings_dir}/*_profile.pkl")
            used_ids = set()
            for profile_file in profile_files:
                try:
                    filename = os.path.basename(profile_file)
                    if filename.startswith('SPEAKER_') and '_profile.pkl' in filename:
                        speaker_part = filename.split('_profile.pkl')[0]
                        used_ids.add(speaker_part)
                except:
                    continue
            
            # ìƒˆë¡œìš´ í™”ìë“¤ì—ê²Œ í• ë‹¹ë  IDë“¤ ê³„ì‚°
            new_speaker_ids = []
            counter = 0
            for _ in target_speakers:
                while True:
                    new_id = f"SPEAKER_{counter:02d}"
                    if new_id not in used_ids:
                        new_speaker_ids.append(new_id)
                        used_ids.add(new_id)  # ì¤‘ë³µ ë°©ì§€
                        break
                    counter += 1
                counter += 1
            
            print(f"\n=== ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ì¶”ì¶œ ë° ì €ì¥ ({', '.join(new_speaker_ids)}) ===")
        else:
            print("\n=== í™”ì ì„ë² ë”© ì¶”ì¶œ ë° ì €ì¥ ===")
        
        # ì„ë² ë”© ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        embeddings_dir = "temp/embeddings"
        os.makedirs(embeddings_dir, exist_ok=True)
        
        # í™”ìë³„ ì„ë² ë”© ì €ì¥ì†Œ
        speaker_embeddings = defaultdict(list)
        
        try:
            # ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
            audio_data, sample_rate = librosa.load(audio_file, sr=16000)
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            print(f"ì„ë² ë”© ì¶”ì¶œ ì‹œì‘... (ì´ {len(results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
            
            for idx, result in enumerate(results):
                speaker = result["speaker"]
                start_time = result["start"]
                end_time = result["end"]
                
                # ëŒ€ìƒ í™”ì í•„í„°ë§ (target_speakersê°€ ì§€ì •ëœ ê²½ìš°)
                if target_speakers and speaker not in target_speakers:
                    continue
                
                # í•´ë‹¹ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                start_sample = int(start_time * sample_rate)
                end_sample = int(end_time * sample_rate)
                segment_audio = audio_data[start_sample:end_sample]
                
                # ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ê±´ë„ˆë›°ê¸° (0.5ì´ˆ ë¯¸ë§Œ)
                if len(segment_audio) < sample_rate * 0.5:
                    print(f"ì„¸ê·¸ë¨¼íŠ¸ ë„ˆë¬´ ì§§ìŒ, ê±´ë„ˆë›°ê¸°: {speaker} ({start_time:.1f}s-{end_time:.1f}s)")
                    continue
                
                try:
                    # ì„ë² ë”© ì¶”ì¶œ
                    embedding_vector = self.extract_single_segment_embedding(audio_file, result)
                    
                    if embedding_vector is None:
                        continue
                    
                    # í™”ìë³„ ì„ë² ë”© ì €ì¥
                    speaker_embeddings[speaker].append({
                        'embedding': embedding_vector,
                        'start_time': start_time,
                        'end_time': end_time,
                        'duration': end_time - start_time,
                        'text': result['text'],
                        'timestamp': current_time
                    })
                    
                    print(f"[{idx+1:2d}/{len(results)}] ì„ë² ë”© ì¶”ì¶œ: {speaker} ({start_time:.1f}s-{end_time:.1f}s) - ì°¨ì›: {embedding_vector.shape}")
                    
                except Exception as e:
                    print(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨ ({speaker}, {idx}): {e}")
            
            # í™”ìë³„ ì„ë² ë”© ë°ì´í„° ì €ì¥
            print(f"\nì„ë² ë”© ë°ì´í„° ì €ì¥ ì¤‘...")
            total_embeddings = 0
            saved_speaker_mapping = {}  # ì›ë˜ ID -> ìƒˆ ID ë§¤í•‘
            
            for speaker, embeddings in speaker_embeddings.items():
                if not embeddings:
                    continue
                
                # ìƒˆë¡œìš´ í™”ì ID í• ë‹¹ (DynamoDB ê¸°ë°˜)
                new_speaker_id = self.speaker_service.get_next_available_speaker_id()
                saved_speaker_mapping[speaker] = new_speaker_id
                
                # ê°œë³„ ì„ë² ë”© íŒŒì¼ ì €ì¥ (ë¡œì»¬)
                embedding_file = os.path.join(embeddings_dir, f"{new_speaker_id}_embeddings.pkl")
                with open(embedding_file, 'wb') as f:
                    pickle.dump(embeddings, f)
                
                # í‰ê·  ì„ë² ë”© ê³„ì‚° (í™”ì ëŒ€í‘œ ë²¡í„°)
                all_embeddings = np.array([emb['embedding'] for emb in embeddings])
                mean_embedding = np.mean(all_embeddings, axis=0)
                std_embedding = np.std(all_embeddings, axis=0)
                
                # í™”ì í”„ë¡œíŒŒì¼ ì €ì¥ (ë¡œì»¬)
                speaker_profile = {
                    'speaker_id': new_speaker_id,
                    'original_label': speaker,
                    'mean_embedding': mean_embedding,
                    'std_embedding': std_embedding,
                    'num_segments': len(embeddings),
                    'total_duration': sum([emb['duration'] for emb in embeddings]),
                    'timestamp': current_time,
                    'audio_file': audio_file,
                    'embedding_dim': mean_embedding.shape[0],
                    'sample_embeddings': embeddings[:3] if len(embeddings) > 3 else embeddings  # ìƒ˜í”Œ ì €ì¥
                }
                
                profile_file = os.path.join(embeddings_dir, f"{new_speaker_id}_profile.pkl")
                with open(profile_file, 'wb') as f:
                    pickle.dump(speaker_profile, f)
                
                # S3ì— í™”ìë³„ í´ë”ë¡œ ì—…ë¡œë“œ
                self._upload_speaker_files_to_s3(new_speaker_id, embedding_file, profile_file)
                
                # DynamoDBì— í™”ì ì •ë³´ ì €ì¥ (ê¸°ë³¸ ì´ë¦„ì€ speaker_id)
                result = self.speaker_service.create_or_update_speaker_name(new_speaker_id, new_speaker_id)
                if not result['success']:
                    print(f"âŒ í™”ì {new_speaker_id} DynamoDB ì €ì¥ ì‹¤íŒ¨: {result['error']}")
                else:
                    print(f"âœ… í™”ì {new_speaker_id} DynamoDB ì €ì¥ ì™„ë£Œ: {result['action']}")
                
                total_embeddings += len(embeddings)
                print(f"âœ… {new_speaker_id} í”„ë¡œíŒŒì¼ ì €ì¥: {profile_file}")
                print(f"   - ì›ë³¸ ë¼ë²¨: {speaker}")
                print(f"   - ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(embeddings)}")
                print(f"   - ì´ ë°œí™” ì‹œê°„: {speaker_profile['total_duration']:.2f}ì´ˆ")
                print(f"   - ì„ë² ë”© ì°¨ì›: {mean_embedding.shape[0]}")
            
            # ì „ì²´ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥
            session_metadata = {
                'timestamp': current_time,
                'audio_file': audio_file,
                'speakers': list(speaker_embeddings.keys()),
                'saved_speaker_mapping': saved_speaker_mapping,
                'total_segments': len(results),
                'total_embeddings': total_embeddings,
                'embedding_dim': mean_embedding.shape[0] if speaker_embeddings else 0,
                'sample_rate': sample_rate
            }
            
            metadata_file = os.path.join(embeddings_dir, f"{current_time}_session_metadata.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(session_metadata, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ‰ ì„ë² ë”© ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {embeddings_dir}/")
            print(f"ğŸ“Š ì´ ì„ë² ë”© ìˆ˜: {total_embeddings}ê°œ")
            print(f"ğŸ‘¥ ìƒˆë¡œ ì €ì¥ëœ í™”ì ìˆ˜: {len(speaker_embeddings)}ëª…")
            print(f"ğŸ”„ í™”ì ID ë§¤í•‘: {saved_speaker_mapping}")
            
            return speaker_embeddings, session_metadata, saved_speaker_mapping
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}, {}, {}
    
    def _upload_speaker_files_to_s3(self, speaker_id, embedding_file_path, profile_file_path):
        """í™”ìë³„ ì„ë² ë”© ë° í”„ë¡œíŒŒì¼ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ"""
        try:
            print(f"ğŸ“¤ S3 ì—…ë¡œë“œ ì‹œì‘: {speaker_id}")
            
            # S3 ê²½ë¡œ êµ¬ì¡°: speakers/{speaker_id}/embeddings.pkl, speakers/{speaker_id}/profile.pkl
            embedding_s3_key = f"speakers/{speaker_id}/embeddings.pkl"
            profile_s3_key = f"speakers/{speaker_id}/profile.pkl"
            
            # ì„ë² ë”© íŒŒì¼ ì—…ë¡œë“œ
            embedding_result = self.s3_service.upload_file(
                file_path=embedding_file_path,
                object_key=embedding_s3_key,
                file_type="speaker_data"
            )
            
            if embedding_result['success']:
                print(f"   âœ… ì„ë² ë”© íŒŒì¼ S3 ì—…ë¡œë“œ ì™„ë£Œ: {embedding_s3_key}")
            else:
                print(f"   âŒ ì„ë² ë”© íŒŒì¼ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {embedding_result.get('error', 'Unknown error')}")
            
            # í”„ë¡œíŒŒì¼ íŒŒì¼ ì—…ë¡œë“œ
            profile_result = self.s3_service.upload_file(
                file_path=profile_file_path,
                object_key=profile_s3_key,
                file_type="speaker_data"
            )
            
            if profile_result['success']:
                print(f"   âœ… í”„ë¡œíŒŒì¼ íŒŒì¼ S3 ì—…ë¡œë“œ ì™„ë£Œ: {profile_s3_key}")
            else:
                print(f"   âŒ í”„ë¡œíŒŒì¼ íŒŒì¼ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {profile_result.get('error', 'Unknown error')}")
            
            # ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
            return embedding_result['success'] and profile_result['success']
            
        except Exception as e:
            print(f"âŒ S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({speaker_id}): {e}")
            return False
    
    def _load_speaker_profiles_from_s3(self):
        """S3ì—ì„œ ëª¨ë“  í™”ì í”„ë¡œíŒŒì¼ì„ ë¡œë“œ"""
        try:
            print("ğŸ” S3ì—ì„œ í™”ì í”„ë¡œíŒŒì¼ ë¡œë“œ ì¤‘...")
            
            # S3ì—ì„œ speakers/ ê²½ë¡œì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
            files_result = self.s3_service.list_files(prefix="speakers/")
            
            if not files_result['success']:
                print(f"âŒ S3 íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {files_result.get('error', 'Unknown error')}")
                return {}
            
            # profile.pkl íŒŒì¼ë“¤ë§Œ í•„í„°ë§
            profile_files = [f for f in files_result['files'] if f['key'].endswith('/profile.pkl')]
            print(f"ğŸ“ S3ì—ì„œ {len(profile_files)}ê°œì˜ í”„ë¡œíŒŒì¼ íŒŒì¼ ë°œê²¬")
            
            existing_profiles = {}
            temp_dir = "temp/s3_cache"
            os.makedirs(temp_dir, exist_ok=True)
            
            for file_info in profile_files:
                try:
                    s3_key = file_info['key']
                    # speakers/SPEAKER_XX/profile.pklì—ì„œ SPEAKER_XX ì¶”ì¶œ
                    speaker_id = s3_key.split('/')[1]
                    
                    # ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
                    local_temp_path = os.path.join(temp_dir, f"{speaker_id}_profile.pkl")
                    download_result = self.s3_service.download_file(s3_key, local_temp_path)
                    
                    if download_result['success']:
                        # í”„ë¡œíŒŒì¼ ë¡œë“œ
                        with open(local_temp_path, 'rb') as f:
                            profile = pickle.load(f)
                            existing_profiles[speaker_id] = profile
                            print(f"âœ… S3ì—ì„œ í™”ì í”„ë¡œíŒŒì¼ ë¡œë“œ: {speaker_id} ({profile['num_segments']}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
                        
                        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        os.remove(local_temp_path)
                    else:
                        print(f"âŒ í”„ë¡œíŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({s3_key}): {download_result.get('error', 'Unknown error')}")
                        
                except Exception as e:
                    print(f"âŒ í”„ë¡œíŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({s3_key}): {e}")
                    continue
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            try:
                os.rmdir(temp_dir)
            except:
                pass
            
            print(f"ğŸ‰ S3ì—ì„œ ì´ {len(existing_profiles)}ëª…ì˜ í™”ì í”„ë¡œíŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            return existing_profiles
            
        except Exception as e:
            print(f"âŒ S3 í”„ë¡œíŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def verify_speakers_against_profiles(self, audio_file, results):
        """ê¸°ì¡´ í™”ì í”„ë¡œíŒŒì¼ê³¼ ë¹„êµí•˜ì—¬ í™”ì ê²€ì¦ ë° ìƒˆë¡œìš´ í™”ì ì €ì¥"""
        try:
            # S3ì—ì„œ ê¸°ì¡´ í”„ë¡œíŒŒì¼ ë¡œë“œ
            existing_profiles = self._load_speaker_profiles_from_s3()
            
            # S3ì—ì„œ ë¡œë“œëœ í”„ë¡œíŒŒì¼ì´ ì—†ìœ¼ë©´ ë¡œì»¬ì—ì„œë„ í™•ì¸ (fallback)
            if not existing_profiles:
                print("ğŸ“‚ S3ì—ì„œ í”„ë¡œíŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¡œì»¬ fallback ì‹œë„...")
                embeddings_dir = "temp/embeddings"
                os.makedirs(embeddings_dir, exist_ok=True)
                
                # í”„ë¡œíŒŒì¼ íŒŒì¼ ê²€ìƒ‰
                profile_files = glob.glob(f"{embeddings_dir}/*_profile.pkl")
                print(f"ğŸ” ë¡œì»¬ í”„ë¡œíŒŒì¼ íŒŒì¼ ê²€ìƒ‰: {len(profile_files)}ê°œ ë°œê²¬")
                
                for profile_file in profile_files:
                    try:
                        with open(profile_file, 'rb') as f:
                            profile = pickle.load(f)
                            speaker_id = profile['speaker_id']
                            existing_profiles[speaker_id] = profile
                            print(f"âœ… ë¡œì»¬ í™”ì ë¡œë“œ: {speaker_id} ({profile['num_segments']}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
                    except Exception as e:
                        print(f"âŒ ë¡œì»¬ í”„ë¡œíŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({profile_file}): {e}")
                        continue
            
            if not existing_profiles:
                print("ğŸ“ ê¸°ì¡´ ë“±ë¡ëœ í™”ìê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í™”ìë¥¼ ìƒˆë¡œ ë“±ë¡í•©ë‹ˆë‹¤.")
                # ëª¨ë“  í™”ìì— ëŒ€í•´ ì„ë² ë”© ì €ì¥
                speaker_embeddings, session_metadata, saved_speaker_mapping = self.extract_and_save_embeddings(audio_file, results)
                
                # ìƒˆë¡œìš´ í™”ìë“¤ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ ë°˜í™˜
                verified_speakers = {}
                for original_speaker, new_speaker_id in saved_speaker_mapping.items():
                    verified_speakers[original_speaker] = {
                        'identified_as': f"ìƒˆë¡œìš´_í™”ì_{new_speaker_id}",
                        'confidence': 'ì‹ ê·œë“±ë¡',
                        'similarity': 0.0,
                        'is_known': False,
                        'new_speaker_id': new_speaker_id
                    }
                
                return verified_speakers
            
            print(f"ğŸ” ì´ {len(existing_profiles)}ëª…ì˜ ê¸°ì¡´ í™”ìì™€ ì‚¬ì „ ë¹„êµ ì¤‘...")
            
            # ê° í™”ìë³„ ëŒ€í‘œ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê²€ì¦
            current_speakers = {}
            for result in results:
                speaker = result["speaker"]
                if speaker not in current_speakers:
                    current_speakers[speaker] = []
                current_speakers[speaker].append(result)
            
            verified_speakers = {}
            speakers_to_save = []  # ìƒˆë¡œìš´ í™”ìë“¤ë§Œ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            
            for current_speaker, speaker_segments in current_speakers.items():
                print(f"\nğŸ¯ {current_speaker} ì‚¬ì „ ê²€ì¦ ì¤‘...")
                
                # ê°€ì¥ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
                longest_segment = max(speaker_segments, key=lambda x: x['end'] - x['start'])
                
                # ëŒ€í‘œ ì„ë² ë”© ì¶”ì¶œ
                representative_embedding = self.extract_single_segment_embedding(audio_file, longest_segment)
                
                if representative_embedding is None:
                    print(f"   âŒ ëŒ€í‘œ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨")
                    speakers_to_save.append(current_speaker)
                    verified_speakers[current_speaker] = {
                        'identified_as': f"ìƒˆë¡œìš´_í™”ì_{current_speaker}",
                        'confidence': 'ì„ë² ë”©ì¶”ì¶œì‹¤íŒ¨',
                        'similarity': 0.0,
                        'is_known': False
                    }
                    continue
                
                # ê¸°ì¡´ í™”ìë“¤ê³¼ ë¹„êµ
                best_match = None
                best_similarity = 0
                all_similarities = {}
                
                for existing_speaker, profile in existing_profiles.items():
                    existing_mean = profile['mean_embedding']
                    
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = cosine_similarity(
                        representative_embedding.reshape(1, -1), 
                        existing_mean.reshape(1, -1)
                    )[0][0]
                    
                    all_similarities[existing_speaker] = similarity
                    
                    if similarity > best_similarity:
                        best_similarity = similarity
                        best_match = existing_speaker
                
                # ì„ê³„ê°’ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ (0.6 ì‚¬ìš©)
                threshold = 0.6
                
                if best_similarity >= threshold:
                    # ê¸°ì¡´ í™”ìë¡œ ì¸ì‹ëœ ê²½ìš° - DynamoDBì—ì„œ ì‹¤ì œ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    display_name = self.speaker_service.get_display_name(best_match)
                    identified_as = display_name
                    confidence_level = "ë†’ìŒ" if best_similarity >= 0.8 else "ë³´í†µ"
                    is_known = True
                    matched_speaker_id = best_match
                    print(f"   âœ… ê¸°ì¡´ í™”ì ë§¤ì¹­: {best_match} -> {display_name} (ìœ ì‚¬ë„: {best_similarity:.4f}, ì‹ ë¢°ë„: {confidence_level})")
                    print(f"   ğŸ’¾ ì„ë² ë”© ì €ì¥ ìƒëµ - ê¸°ì¡´ í”„ë¡œí•„ ì¬ì‚¬ìš©")
                else:
                    identified_as = f"ìƒˆë¡œìš´_í™”ì_{current_speaker}"
                    confidence_level = "ìƒˆë¡œìš´í™”ì"
                    is_known = False
                    matched_speaker_id = None
                    speakers_to_save.append(current_speaker)
                    print(f"   â“ ìƒˆë¡œìš´ í™”ì: {identified_as} (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.4f})")
                    print(f"   ğŸ’¾ ì„ë² ë”© ì €ì¥ ì˜ˆì •")
                
                # ìƒìœ„ 3ê°œ ìœ ì‚¬ë„ ì¶œë ¥
                sorted_similarities = sorted(all_similarities.items(), key=lambda x: x[1], reverse=True)
                print(f"   ğŸ“Š ìœ ì‚¬ë„ ìˆœìœ„:")
                for i, (speaker, sim) in enumerate(sorted_similarities[:3], 1):
                    status = "âœ…" if sim >= threshold else "âŒ"
                    print(f"      {status} {i}ìœ„: {speaker} ({sim:.4f})")
                
                verified_speakers[current_speaker] = {
                    'identified_as': identified_as,
                    'confidence': confidence_level,
                    'similarity': best_similarity,
                    'is_known': is_known,
                    'matched_speaker_id': matched_speaker_id,
                    'all_similarities': all_similarities
                }
            
            print(f"\nğŸ‰ ì‚¬ì „ ê²€ì¦ ì™„ë£Œ!")
            print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
            total_speakers = len(verified_speakers)
            known_count = sum(1 for v in verified_speakers.values() if v['is_known'])
            new_count = len(verified_speakers) - known_count
            print(f"   - ì „ì²´ í™”ì: {total_speakers}ëª…")
            print(f"   - ê¸°ì¡´ í™”ì: {known_count}ëª… (ì„ë² ë”© ì €ì¥ ìƒëµ)")
            print(f"   - ìƒˆë¡œìš´ í™”ì: {new_count}ëª… (ì„ë² ë”© ì €ì¥ ì§„í–‰)")
            
            # ìƒˆë¡œìš´ í™”ìë“¤ì— ëŒ€í•´ì„œë§Œ ì „ì²´ ì„ë² ë”© ì €ì¥
            if speakers_to_save:
                print(f"\nğŸ’¾ ìƒˆë¡œìš´ í™”ìë“¤ì— ëŒ€í•œ ì„ë² ë”© ì €ì¥ ì‹œì‘...")
                
                # ìƒˆë¡œìš´ í™”ìë“¤ì˜ ê²°ê³¼ë§Œ í•„í„°ë§
                new_speaker_results = [r for r in results if r['speaker'] in speakers_to_save]
                
                # ì„ë² ë”© ì¶”ì¶œ ë° ì €ì¥ (ìƒˆë¡œìš´ í™”ìë“¤ë§Œ)
                new_speaker_embeddings, session_metadata, saved_speaker_mapping = self.extract_and_save_embeddings(
                    audio_file, new_speaker_results, speakers_to_save
                )
                
                # ìƒˆë¡œ ì €ì¥ëœ í™”ìë“¤ì˜ ì •ë³´ ì—…ë°ì´íŠ¸
                for original_speaker, new_speaker_id in saved_speaker_mapping.items():
                    if original_speaker in verified_speakers:
                        verified_speakers[original_speaker]['identified_as'] = f"ìƒˆë¡œìš´_í™”ì_{new_speaker_id}"
                        verified_speakers[original_speaker]['new_speaker_id'] = new_speaker_id
            
            return verified_speakers
            
        except Exception as e:
            print(f"âŒ í™”ì ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def generate_speaker_summary(self, results):
        """í™”ìë³„ ë°œí™” ìš”ì•½ ìƒì„±"""
        speaker_summary = {}
        for result in results:
            # í™”ì í‚¤ ê²°ì • (ê¸°ì¡´ í™”ìë©´ ì‹¤ì œ ì´ë¦„, ìƒˆë¡œìš´ í™”ìë©´ speaker_id ì‚¬ìš©)
            if result.get('is_known_speaker'):
                # ê¸°ì¡´ í™”ìì¸ ê²½ìš° ì‹¤ì œ ì´ë¦„ ì‚¬ìš©
                speaker_key = result.get("verified_speaker") or result.get("speaker_id", "UNKNOWN")
            else:
                # ìƒˆë¡œìš´ í™”ìì¸ ê²½ìš° speaker_id ì‚¬ìš©
                speaker_key = result.get("speaker_id") or result.get("verified_speaker") or result.get("speaker", "UNKNOWN")
            
            if speaker_key not in speaker_summary:
                speaker_summary[speaker_key] = {
                    "total_duration": 0,
                    "segment_count": 0,
                    "texts": []
                }
            
            speaker_summary[speaker_key]["total_duration"] += float(result["duration"])
            speaker_summary[speaker_key]["segment_count"] += 1
            speaker_summary[speaker_key]["texts"].append(result["text"])
        
        return speaker_summary
    
    # ê²°ê³¼ê°’ í™•ì¸ìš© / ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œì—ëŠ” í•„ìš”í•˜ì§€ ì•Šì€ ê¸°ëŠ¥
    def save_transcript_to_file(self, results, speaker_summary, verified_speakers, processing_info):
        """STT ê²°ê³¼ë¥¼ ê°€ë…ì„± ì¢‹ì€ ëŒ€í™”ë¡ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
            result_dir = "temp/result"
            os.makedirs(result_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            transcript_filename = f"transcript_{timestamp}.txt"
            transcript_path = os.path.join(result_dir, transcript_filename)
            
            with open(transcript_path, 'w', encoding='utf-8') as f:
                # í—¤ë” ì •ë³´ ì‘ì„±
                f.write("=" * 80 + "\n")
                f.write("                          ìŒì„± ì¸ì‹ ëŒ€í™”ë¡\n")
                f.write("=" * 80 + "\n")
                f.write(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ')}\n")
                f.write(f"ì´ ì²˜ë¦¬ ì‹œê°„: {processing_info.get('total_time', 0):.2f}ì´ˆ\n")
                f.write(f"ì´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {processing_info.get('total_segments', 0)}ê°œ\n")
                f.write(f"ì¸ì‹ëœ í™”ì ìˆ˜: {processing_info.get('unique_speakers', 0)}ëª…\n")
                f.write("\n")
                
                # í™”ì ì •ë³´ ìš”ì•½
                f.write("-" * 50 + "\n")
                f.write("í™”ì ì •ë³´ ìš”ì•½\n")
                f.write("-" * 50 + "\n")
                for speaker, info in speaker_summary.items():
                    f.write(f"â€¢ {speaker}\n")
                    f.write(f"  - ì´ ë°œí™” ì‹œê°„: {info['total_duration']:.1f}ì´ˆ\n")
                    f.write(f"  - ë°œí™” íšŸìˆ˜: {info['segment_count']}íšŒ\n")
                    
                    # ê²€ì¦ ì •ë³´ ì¶”ê°€
                    original_speaker = None
                    for orig, verified_info in verified_speakers.items():
                        if verified_info['identified_as'] == speaker:
                            original_speaker = orig
                            break
                    
                    if original_speaker and verified_speakers.get(original_speaker):
                        verify_info = verified_speakers[original_speaker]
                        f.write(f"  - í™”ì ì¸ì‹: {verify_info['confidence']}")
                        if verify_info['is_known']:
                            f.write(f" (ìœ ì‚¬ë„: {verify_info['similarity']:.2f})")
                        elif verify_info.get('new_speaker_id'):
                            f.write(f" (ìƒˆ ID: {verify_info['new_speaker_id']})")
                        f.write("\n")
                    f.write("\n")
                
                # ëŒ€í™”ë¡ ë³¸ë¬¸
                f.write("=" * 80 + "\n")
                f.write("                            ëŒ€í™”ë¡ ë³¸ë¬¸\n")
                f.write("=" * 80 + "\n\n")
                
                # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ëŒ€í™”ë¡ í˜•íƒœë¡œ ì‘ì„±
                sorted_results = sorted(results, key=lambda x: x['start'])
                
                for i, result in enumerate(sorted_results, 1):
                    # ì‹œê°„ ì •ë³´ë¥¼ ë¶„:ì´ˆ í˜•íƒœë¡œ ë³€í™˜
                    start_min = int(result['start'] // 60)
                    start_sec = int(result['start'] % 60)
                    end_min = int(result['end'] // 60)
                    end_sec = int(result['end'] % 60)
                    
                    # í™”ìëª… ê²°ì • (ê¸°ì¡´ í™”ìë©´ ì‹¤ì œ ì´ë¦„, ìƒˆë¡œìš´ í™”ìë©´ speaker_id ì‚¬ìš©)
                    if result.get('is_known_speaker'):
                        # ê¸°ì¡´ í™”ìì¸ ê²½ìš° ì‹¤ì œ ì´ë¦„ ì‚¬ìš©
                        speaker_name = result.get('verified_speaker', result.get('speaker_id', 'UNKNOWN'))
                    else:
                        # ìƒˆë¡œìš´ í™”ìì¸ ê²½ìš° speaker_id ì‚¬ìš©
                        speaker_name = result.get('speaker_id') or result.get('verified_speaker', result.get('speaker', 'UNKNOWN'))
                    
                    # ëŒ€í™”ë¡ í˜•íƒœë¡œ ì‘ì„±
                    f.write(f"[{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}] {speaker_name}\n")
                    f.write(f"{result['text']}\n")
                    
                    # í™”ì ê²€ì¦ ì •ë³´ (ìƒì„¸ ëª¨ë“œ)
                    if result.get('is_known_speaker') is not None:
                        confidence = result.get('verification_confidence', 'N/A')
                        similarity = result.get('similarity_score', 0)
                        original_label = result.get('original_speaker_label', '')
                        
                        f.write(f"(ê²€ì¦: {confidence}")
                        if similarity > 0:
                            f.write(f", ìœ ì‚¬ë„: {similarity:.2f}")
                        if original_label:
                            f.write(f", ì›ë³¸: {original_label}")
                        f.write(")\n")
                    
                    f.write("\n")
                
                # í‘¸í„°
                f.write("=" * 80 + "\n")
                f.write("                          ëŒ€í™”ë¡ ì¢…ë£Œ\n")
                f.write("=" * 80 + "\n")
            
            print(f"ëŒ€í™”ë¡ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {transcript_path}")
            
            # S3ì— ëŒ€í™”ë¡ íŒŒì¼ ì—…ë¡œë“œ (ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ ë™ì¼í•œ ê²½ë¡œ êµ¬ì¡°)
            s3_transcript_path = self._upload_transcript_to_s3(transcript_path, timestamp)
            
            return transcript_path
            
        except Exception as e:
            print(f"ëŒ€í™”ë¡ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _upload_transcript_to_s3(self, transcript_path, timestamp):
        """ëŒ€í™”ë¡ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ (ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ ë™ì¼í•œ ê²½ë¡œ êµ¬ì¡°)"""
        try:
            from datetime import datetime
            now = datetime.now()
            
            # íŒŒì¼ëª… ìƒì„±: transcript_yyyymmdd_HHMMSS.txt
            transcript_filename = f"transcript_{timestamp}.txt"
            
            # S3 í‚¤ ìƒì„±: audio/yyyy/mm/transcript_íŒŒì¼ëª… (ì˜¤ë””ì˜¤ì™€ ë™ì¼í•œ ê²½ë¡œ)
            s3_key = f"audio/{now.strftime('%Y')}/{now.strftime('%m')}/{transcript_filename}"
            
            print(f"ğŸ“¤ ëŒ€í™”ë¡ íŒŒì¼ S3 ì—…ë¡œë“œ: {s3_key}")
            
            # S3ì— ì—…ë¡œë“œ
            result = self.s3_service.upload_file(
                file_path=transcript_path,
                object_key=s3_key,
                file_type="transcript"
            )
            
            if result['success']:
                print(f"âœ… ëŒ€í™”ë¡ íŒŒì¼ S3 ì—…ë¡œë“œ ì™„ë£Œ: {s3_key}")
                return s3_key
            else:
                print(f"âŒ ëŒ€í™”ë¡ íŒŒì¼ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                return None
                
        except Exception as e:
            print(f"âŒ ëŒ€í™”ë¡ íŒŒì¼ S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def cleanup_files(self, original_file_path, converted_file_path):
        """ì—…ë¡œë“œëœ ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬"""
        try:
            # ì›ë³¸ íŒŒì¼ ì‚­ì œ
            if os.path.exists(original_file_path):
                os.remove(original_file_path)
                print(f"ì›ë³¸ íŒŒì¼ ì‚­ì œë¨: {original_file_path}")
            
            # ë³€í™˜ëœ WAV íŒŒì¼ ì‚­ì œ (ì›ë³¸ê³¼ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ)
            if converted_file_path != original_file_path and os.path.exists(converted_file_path):
                os.remove(converted_file_path)
                print(f"ë³€í™˜ëœ íŒŒì¼ ì‚­ì œë¨: {converted_file_path}")
                
        except Exception as e:
            print(f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
